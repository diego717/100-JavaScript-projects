{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diego717/100-JavaScript-projects/blob/main/split_then_refine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s3VjY_bpXR8"
      },
      "source": [
        "This Colab contains the Official demo of our AAAI21 paper:\n",
        "\n",
        "[**Split then Refine: Stacked Attention-guided ResUNets for Blind Single Image Visible Watermark Removal**](https://arxiv.org/abs/2012.07007)\n",
        "\n",
        "Xiaodong Cun, Chi-Man Pun*\n",
        "\n",
        "University of Macau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r73ZJv4bpTVD",
        "outputId": "68e27fa8-47c6-435f-9853-46d4f4693ea1"
      },
      "source": [
        "# download the necessary componments\n",
        "! rm -rf *\n",
        "! git clone https://github.com/vinthony/deep-blind-watermark-removal.git # get code from github\n",
        "! gdown https://drive.google.com/uc?id=1KpSJ6385CHN6WlAINqB3CYrJdleQTJBc # get pretrained model\n",
        "! gdown https://drive.google.com/uc?id=18HaWfYYZCD34VttSjd2at8b9BKdhgVgU && unzip -q val.zip # get validation dataset (2.31G) of 27kpng\n",
        "! gdown https://drive.google.com/uc?id=1it5oQDRqRzBVieX6jKNmOxj1992f63yM && unzip -q natural.zip # get natural images (0.4G) of 27kpng\n",
        "\n",
        "# rename natural images\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "filenames = [ shutil.copy(join('./natural', f), join('./natural', f).split('-')[0]+'.jpg') for f in listdir('./natural') if isfile(join('./natural', f)) ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-blind-watermark-removal'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 89 (delta 25), reused 56 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (89/89), 50.87 KiB | 2.12 MiB/s, done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KpSJ6385CHN6WlAINqB3CYrJdleQTJBc\n",
            "To: /content/27kpng_model_best.pth.tar\n",
            "100% 131M/131M [00:03<00:00, 33.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18HaWfYYZCD34VttSjd2at8b9BKdhgVgU\n",
            "To: /content/val.zip\n",
            "100% 2.31G/2.31G [00:41<00:00, 55.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "-iYvIp3kpJpq",
        "outputId": "79423388-4346-45e0-9127-c39b53eed22e"
      },
      "source": [
        "import os, sys, torch,random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "sys.path.append('deep-blind-watermark-removal')\n",
        "sys.path.insert(0,'deep-blind-watermark-removal')\n",
        "\n",
        "from scripts.utils.imutils import im_to_numpy\n",
        "import scripts.models as models\n",
        "import scripts.datasets as datasets\n",
        "%matplotlib inline\n",
        "from PIL import Image, ImageChops\n",
        "\n",
        "def get_jet():\n",
        "    colormap_int = np.zeros((256, 3), np.uint8)\n",
        " \n",
        "    for i in range(0, 256, 1):\n",
        "        colormap_int[i, 0] = np.int_(np.round(cm.jet(i)[0] * 255.0))\n",
        "        colormap_int[i, 1] = np.int_(np.round(cm.jet(i)[1] * 255.0))\n",
        "        colormap_int[i, 2] = np.int_(np.round(cm.jet(i)[2] * 255.0))\n",
        "\n",
        "    return colormap_int\n",
        "\n",
        "def clamp(num, min_value, max_value):\n",
        "    return max(min(num, max_value), min_value)\n",
        "\n",
        "def gray2color(gray_array, color_map):\n",
        "    \n",
        "    rows, cols = gray_array.shape\n",
        "    color_array = np.zeros((rows, cols, 3), np.uint8)\n",
        " \n",
        "    for i in range(0, rows):\n",
        "        for j in range(0, cols):\n",
        "#             log(256,2) = 8 , log(1,2) = 0 * 8\n",
        "            color_array[i, j] = color_map[clamp(int(abs(gray_array[i, j])*10),0,255)]\n",
        "    \n",
        "    return color_array\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        d = dict(*args, **kwargs)\n",
        "        self.__dict__ = d\n",
        "\n",
        "jet_map = get_jet()\n",
        "\n",
        "resume_path = '27kpng_model_best.pth.tar' # path of pretrained model\n",
        "samples = [320,1364,1868] #random.sample(range(4000), 1) # show random sample \n",
        "\n",
        "data_config  = objectview({'input_size':256,\n",
        "                            'limited_dataset':0,\n",
        "                            'normalized_input':False,\n",
        "                            'data_augumentation':False,\n",
        "                            'base_dir':'.',\n",
        "                            'data':'_images'})\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(datasets.COCO('val',config=data_config,sample=samples))\n",
        "\n",
        "print('input          | target              | coarser            | final')\n",
        "print('----------------------------------------------------------------------------')\n",
        "print('predicted mask | predicted watermark | coarser difference | final difference')\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "      model = models.__dict__['vvv4n']().cuda()\n",
        "      model.load_state_dict(torch.load(resume_path)['state_dict'])\n",
        "      model.eval()\n",
        "      \n",
        "      for i, batches in enumerate(val_loader):\n",
        "          \n",
        "          plt.figure(figsize=(48,12))\n",
        "\n",
        "          im,mask,target = batches['image'].cuda(),batches['mask'].cuda(),batches['target'].cuda()\n",
        "              \n",
        "          imoutput,immask,imwatermark = model(im)\n",
        "        \n",
        "          imcoarser,imrefine,imwatermark = imoutput[1]*immask + im*(1-immask),imoutput[0]*immask + im*(1-immask),imwatermark*immask\n",
        "\n",
        "          ims1 = im_to_numpy(torch.clamp(torch.cat([im,target,imcoarser,imrefine],dim=3)[0]*255,min=0.0,max=255.0)).astype(np.uint8)\n",
        "          \n",
        "          imcoarser, imrefine, target  = im_to_numpy((imcoarser[0]*255)).astype(np.uint8), im_to_numpy((imrefine[0]*255)).astype(np.uint8), im_to_numpy((target[0]*255)).astype(np.uint8)\n",
        "          immask, imwatermark = im_to_numpy((immask.repeat(1,3,1,1)[0]*255)).astype(np.uint8),im_to_numpy((imwatermark[0]*255)).astype(np.uint8)\n",
        "\n",
        "          coarsenp = gray2color(np.array(ImageChops.difference(Image.fromarray(imcoarser),Image.fromarray(target)).convert('L')),jet_map)\n",
        "          finenp = gray2color(np.array(ImageChops.difference(Image.fromarray(imrefine),Image.fromarray(target)).convert('L')),jet_map)\n",
        "          \n",
        "          imfinal = np.concatenate([ims1,np.concatenate([immask,imwatermark,coarsenp,finenp],axis=1)],axis=0)\n",
        "\n",
        "          plt.imshow(imfinal,vmin=0.0,vmax=255.0)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-97209d0f22da>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deep-blind-watermark-removal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mim_to_numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scripts.utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}